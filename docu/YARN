YARN - Yet Another Resource Negotiator

What is YARN?
-separates the problem of managing resources on your cluster from MapReduce
-you don't need to actually write code against YARN yourself in this day and age
-it sits on top of HDFS and below MapReduce, Spark or Tez
-it is the cluster computing resources manager

-Client Node reuquests a job to be executed --> YARN kicks off the Application Master --> Application master then is responsible along with YARN for spinning off more Nodes that excute the original job

-where to run all these appln process, where to spin-off the nodes, how to distribute job across them and optimizing its execution

-you can specify data locality
	-YARN will try to get your process on the same node that has your HDFS

-you can specify different scheduling options for applications
	-FIFO: first in first out
	-Capacity: may run jobs in parallel if there's enough spare capacity
	-Fair Schedulers: may cut into a larger running job if you want to squeeze in a small one







TEZ 
-application built on top of YARN
-uses DAG - Directed Acylic Graph
-makes Hive, Pig, MapReduce job a lot faster
-construct DAG for more efficient processing of distributed jobs
-optimizes physical data flow and resource usage




MESOS
-like yarn another resource negotiator
-not just for big data stuff- it can allocate resources for web servers, small scripts, whatever
-general purrpose system than YARN
-YARN works for just HADOOP-big data
-Spark runs on Mesos
-Hadoop YARN may be integrated with Mesos using Myriad
-YARN is a monolithic scheduler
-Mesos is a 2-tiered system
	-Mesos just makes offers of resources to your application(framework)
	-your framework decides whether to accept or reject them
	-you can also decide your own scheduling algorithm
-YARN is optimized for long, analytical jobs like you see in Hadoop
-Mesos can do that as well as short-lived processess





ZooKeeper
-keeps track of information that must be synchronized across your cluster
	-which node is master?
	-what tasks are assigned to which workers?
	-which workers are currently available?
-an external tool that applications can use to recover from partial failures in your cluster
-an integral part of HBase, High0Availability (HA) MapReduce, Drill, Storm, Solr and much more

Failure Modes ZooKeeper help with
-Master crashes
-Worker crashes
-network Trouble: part of your cluster can't see the rest

Primitive operations in a distributed system
-master election
-crash detection
-group management
-metadata

Persistent and ephemeral znodes
-persistent: remain stored until explicitly deleted
	i.e, assignment of tasks to workers must persist even if master crashes
-ephimeral znodes: goes away if the client that created it crashes or loses its connection to ZooKeeper
	i.e, if the master crashes, it should release its lock on the znode that indicates which node is the master


ZooKeeper quoroms - the number of servers that need to be written to before the task is called success
quorum 2 - it accepts the result if 2 zookeeper servers agree on the same value





OOZIE
-Burmese name for "elephant keeper"
-system for running and scheduling Hadoop tasks
-workflow: tie together differnt actions in Hadoop that depend on one another
-build DAG of actions
	-specified via XML
	-so you can run actions in parallel

OOZIE coordinator:
-schedules workflow execution
-launches workflows based on a given start time and frequency

OOZIE bundles
-bundle is a collection of coordinators 





Apache Zeppelin
-like the ipython notebook
-lets you inteeractively run scripts on your data
-can share notebooks with others in your cluster
-can run Spark code interactively
can execute SQL queries directly against SparkSQL
-visualize queries
-add own interpreters for different backends



HUE - Hadoop User Experience







